# OTTCOUTURE Cannabis Vision OpenCore

OTTCOPS ist der von [ottcouture.eu](https://ottcouture.eu) betriebene Analyzer fÃ¼r Cannabis-Vision. Er kombiniert Teachable-Machine-Modelle mit multimodalen LLMs und liefert strukturierte JSON-Outputs â€“ sachlich, reproduzierbar und vollstÃ¤ndig unter OTTCOUTURE-Rechten. Feedback oder neue Modelle gern an **otcdmin@outlook.com**, Instagram **@ottcouture.eu** oder Discord [`discord.gg/GMMSqePfPh`](https://discord.gg/GMMSqePfPh).

## Feature Highlights
- ğŸŒ¿ **FastAPI Core** mit Analyzer, Config Deck, OTTO-Chat (`/completions`) und dokumentierten `/tm-models*` Routen.
- ğŸ§  **Vision LLM Switchboard** fÃ¼r OpenAI, Ollama oder LM Studio inkl. System-Presetverwaltung.
- ğŸ§ª **Teachable-Machine-Depot** mit ZIP-Uploads (metadata.json, model.json, weights.bin), Registry und Standardauswahl fÃ¼r den Analyzer.
- ğŸ§µ **Model Routing**: Das Frontend kann pro Analyse den gewÃ¼nschten TM-Slot wÃ¤hlen; die Einstellung wird zusÃ¤tzlich serverseitig in `app-settings.json` persistiert.
- ğŸ¤– **OTTO Grow Chat** â€“ eigener Screen fÃ¼r kultivierungsrelevante Fragen mit definiertem System Prompt.
- ğŸ“¡ **WiFi Broadcast Mode** (mDNS/zeroconf) fÃ¼r Hostnamen wie `ottcolab.local` im gesamten WLAN.
OTTCOPS ist unser OpenCore-Playground fÃ¼r nerdige Cannabis Vision Flows, geboren bei [ottcouture.eu](https://ottcouture.eu) und verÃ¶ffentlicht unter der AGPL. Wir mischen Teachable-Machine-Signale mit multimodalen LLMs, streamen rohe JSON-Outputs und behalten sÃ¤mtliche Brand-Rechte bei OTTCOUTURE. Credits & Feedback bitte an **otcdmin@outlook.com** oder im Discord [`discord.gg/GMMSqePfPh`](https://discord.gg/GMMSqePfPh).

## Feature Highlights
- ğŸŒ¿ **FastAPI Core** mit `/analyze`, `/docs`, `/config` und den neuen `/tm-models*`-Routen.
- ğŸ§  **Vision LLM Switchboard**: OpenAI, Ollama oder LM Studio lassen sich live am `/config`-Frontend umstellen.
- ğŸ§ª **Cannabis-Systemprompts & Lightweight-Modelle** fÃ¼r Trichome-Heatmaps, Terpen-Stacks und Glitch-Hunts.
- ğŸ“¦ **Teachable-Machine-Depot**: ZIP-Uploads (metadata.json, model.json, weights.bin) landen versioniert unter `/TM-models` und werden typisiert (Trichomen vs. Health).
- ğŸ›¡ï¸ **Brand Messaging** auf jeder Seite â€“ ottcouture.eu Rechte, Kontaktwege, Discord-CTA.

## Installation im OTTCOUTURE Style
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# optional wenn du GPT Calls willst
export OPENAI_API_KEY="sk-..."

# Dev-Server starten
uvicorn app:app --reload
```

1. Analyzer UI: `http://localhost:8000/`
2. OTTO Grow Chat: `http://localhost:8000/completions`
3. Config Hub inkl. TM-Depot: `http://localhost:8000/config`
4. Discord Crew & Support: [`discord.gg/GMMSqePfPh`](https://discord.gg/GMMSqePfPh)
2. Config Hub inkl. TM-Depot: `http://localhost:8000/config`
3. Discord Crew & Support: [`discord.gg/GMMSqePfPh`](https://discord.gg/GMMSqePfPh)

## Konfiguration
| Variable | Pflicht | Default | Beschreibung |
| --- | --- | --- | --- |
| `OPENAI_API_KEY` | bei OpenAI Flow | â€“ | Key fÃ¼r GPT-4.1 mini oder dein bevorzugtes Vision Modell. |
| `OPENAI_GPT_MODEL` | optional | `gpt-4.1-mini` | LLM-ID fÃ¼r Cloud Vision. |
| `TEACHABLE_MODEL_PATH` | optional | `./models/teachable_model` | Alternativer Pfad zu einem Legacy-Teachable-Model. |

Alle UI-Einstellungen landen im Browser (`localStorage.cannabisLLMConfig`). Die Auswahl des Standard-Teachable-Machine-Modells speichert das Backend zusÃ¤tzlich in `app-settings.json`, damit der Analyzer die Vorgabe auch nach einem Neustart nutzt.

## WiFi Broadcast (ottcolab.local)
1. Installiere die Requirements (wir shippen `zeroconf`, wichtig fÃ¼r mDNS). Falls du ein bestehendes Environment nutzt, fÃ¼hre `pip install zeroconf` aus.
2. Starte `uvicorn app:app --host 0.0.0.0 --port 8000`, sodass der Server im WLAN erreichbar ist.
3. Ã–ffne `http://localhost:8000/config`, scrolle zum Abschnitt â€WiFi Broadcast & ottcolab.localâ€œ.
4. Hostname setzen (wir erzwingen `.local`) und den Port bestÃ¤tigen, anschlieÃŸend â€Broadcast aktivierenâ€œ anklicken.
5. Jetzt sollten Smartphones, Tablets und Desktop-GerÃ¤te im selben Netzwerk `http://ottcolab.local:8000/` aufrufen kÃ¶nnen. Feedback bitte weiterhin an **otcdmin@outlook.com**, Instagram **@ottcouture.eu** oder [Discord](https://discord.gg/GMMSqePfPh).

## Teachable Machine Depot (`/TM-models`)
1. Exportiere dein Google Teachable-Machine-Projekt als **TensorFlow** Paket (enthÃ¤lt `metadata.json`, `model.json`, `weights.bin`).
2. Ã–ffne `http://localhost:8000/config` und nutze den Abschnitt â€OTTCOUTURE Teachable Machine Depotâ€œ.
3. Nach dem Upload landet das Modell unter `/TM-models/<slug>` und wird in `TM-models/registry.json` gefÃ¼hrt.
4. Die Listenansicht erlaubt pro Modell den Status â€Standard im Analyzerâ€œ. Der Standard wird zusÃ¤tzlich in `app-settings.json` notiert.
5. Wird kein Community-Modell ausgewÃ¤hlt, greift der Analyzer auf `TEACHABLE_MODEL_PATH` (OPENCORE Referenz) zurÃ¼ck.

> Pflichtdateien: `metadata.json`, `model.json`, `weights.bin`. Fehlen Bestandteile, lehnt der Upload ab.

## API Routen
- `GET /` â€“ Analyzer Landing Page mit Modellauswahl
- `GET /config` â€“ Self-Host Konfigurator & TM-Depot
- `GET /completions` â€“ OTTO Grow Chat UI
- `POST /analyze` â€“ Bild + Prompt + optional `model_id`
- `POST /api/completions` â€“ OTTO Chat Endpoint (`prompt` im JSON-Body)
- `GET /tm-models` â€“ Registry + Defaultinformationen
- `POST /tm-models/upload` â€“ ZIP Upload (`file`, `model_type`, `display_name`)
- `POST /tm-models/default/{model_id}` â€“ setzt Standardmodell
- `DELETE /tm-models/default` â€“ entfernt Standardmodell
- `GET /network/status`, `POST /network/announce`, `DELETE /network/announce` â€“ mDNS Steuerung
Alle UI-Einstellungen landen im Browser (`localStorage.cannabisLLMConfig`). FÃ¼r Self-Hosted Vision-LLMs (Ollama/LM Studio) kannst du Base URL, Model, Keys und unsere Cannabis-Systemprompts direkt Ã¼bernehmen.

## Teachable Machine Depot (`/TM-models`)
1. Exportiere dein Google Teachable-Machine-Projekt als **TensorFlow** Paket (es enthÃ¤lt `metadata.json`, `model.json`, `weights.bin`).
2. Ã–ffne `http://localhost:8000/config`, scrolle zum Abschnitt â€OTTCOUTURE Teachable Machine Depotâ€œ.
3. Gib einen Modellnamen an, wÃ¤hle den Typ:
   - `Trichomen Analyse` fÃ¼r Reifegrad/QualitÃ¤ts-Modelle.
   - `Health & Leaf Safety` fÃ¼r Symptom- oder Schadens-Detektoren.
4. Lade die ZIP-Datei hoch. Das Backend extrahiert sie nach `/TM-models/<slug>` und ergÃ¤nzt `TM-models/registry.json`.
5. Zwei Starter-Slots liegen bereit: du kannst eigene Basismodelle im Repo-Verzeichnis `TM-models/` ablegen und mit dem Upload-Flow Ã¼berschreiben.

> Wichtig: Jede ZIP muss mindestens `metadata.json`, `model.json` und `weights.bin` enthalten. Fehlende Dateien blocken wir bewusst, damit die Community nur valide Assets sieht.

## API Routen
- `GET /` â€“ Analyzer Landing Page (brandet, Cannabis-Formular)
- `GET /config` â€“ Self-Host Konfigurator & TM-Depot
- `POST /analyze` â€“ Image + Prompt â†’ TM Klassifikation + GPT Antwort
- `GET /tm-models` â€“ Liefert registrierte TM-Modelle samt Metadaten
- `POST /tm-models/upload` â€“ Erwartet `file`, `model_type`, `display_name`

## Projektstruktur
```
.
â”œâ”€â”€ app.py                # FastAPI Service + TM Depot + WiFi Broadcast + OTTO Endpoint
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html        # Analyzer UI inkl. Modellauswahl
â”‚   â”œâ”€â”€ completions.html  # OTTO Grow Chat OberflÃ¤che
â”‚   â””â”€â”€ config.html       # Self-Host + TM Depot OberflÃ¤che
â”œâ”€â”€ TM-models/            # Versionierte Teachable-Machine Bundles (ZIP-Uploads)
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ registry.json     # wird zur Laufzeit gepflegt
â”œâ”€â”€ app-settings.json     # Standardmodell (wird bei Bedarf erzeugt)
â”œâ”€â”€ app.py                # FastAPI Service + TM Depot Uploads
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html        # Analyzer UI (OTTCOUTURE Style)
â”‚   â””â”€â”€ config.html       # Self-Host + TM Depot OberflÃ¤che
â”œâ”€â”€ TM-models/            # Versionierte Teachable Machine Bundles (ZIP-Uploads)
â”‚   â””â”€â”€ README.md         # Hinweise & Slots fÃ¼r Startermodelle
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## Feedback & Rechte
- Brand & Rechte: **ottcouture.eu** â€“ wir verÃ¶ffentlichen hier bewusst OpenCore, aber behalten sÃ¤mtliche Markenrechte.
- Feedback: **otcdmin@outlook.com**, Instagram **@ottcouture.eu**, Discord [`discord.gg/GMMSqePfPh`](https://discord.gg/GMMSqePfPh).
- Lizenz: [AGPL-3.0](LICENSE). Bitte alle Forks/Deployments wieder zur Community spiegeln und Credits lassen.
